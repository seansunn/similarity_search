{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45e0d24-7384-4950-8a42-3d230ec75c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\ProgramData\\Miniconda\\envs\\qlora\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          LlamaTokenizer)\n",
    "from peft import (LoraConfig,\n",
    "                  get_peft_model,\n",
    "                  prepare_model_for_kbit_training)\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8479ae-2a20-4780-98a5-df0a8200fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_from_disk('data/finetuning_llama')['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203d9b00-6c55-4f8d-9065-2f67a1d52035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c310f7451904113b689aab31304a5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify model path\n",
    "model_path = \"llms/Llama-2-13b-chat-hf\"\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        llm_int8_threshold=6.0,\n",
    "        llm_int8_has_fp16_weight=False,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    ),\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2bb66cb-33de-4b90-960a-bfea4756dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175a69d3-029a-47f6-8637-e3234475334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT preparation\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b51760-c95f-4016-8eb1-48a1d6ac6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT LoRA configuration\n",
    "# github.com/artidoro/qlora/blob/main/qlora.py\n",
    "def find_linear(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "modules = find_linear(model)\n",
    "peft_config = LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "for name, module in model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cedc8bc7-2aa3-4e4e-b9e7-538eb718d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "# github.com/artidoro/qlora/blob/main/qlora.py\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=20,\n",
    "    save_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    output_dir=\"checkpoints/llama_128\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0646fe24-1045-4dcf-949f-95f70b7d3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup STFTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"conversation\",\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    args=training_arguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd39b43-aa00-412b-b0ac-540af4964646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msean-sun-22\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639a75c263dc441db95e3e24d5230642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\LLM\\wandb\\run-20230825_154726-5fuuuvb8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sean-sun-22/huggingface/runs/5fuuuvb8' target=\"_blank\">stilted-firefly-12</a></strong> to <a href='https://wandb.ai/sean-sun-22/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sean-sun-22/huggingface' target=\"_blank\">https://wandb.ai/sean-sun-22/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sean-sun-22/huggingface/runs/5fuuuvb8' target=\"_blank\">https://wandb.ai/sean-sun-22/huggingface/runs/5fuuuvb8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 30:50, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.593500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.178000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=1.2219526637684215, metrics={'train_runtime': 1876.7845, 'train_samples_per_second': 0.948, 'train_steps_per_second': 0.059, 'total_flos': 4.06198408691712e+16, 'train_loss': 1.2219526637684215, 'epoch': 1.98})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bcd3e1-b316-4f5a-80ee-f621216ab457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora/llama_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76d1941-4d11-49bf-86ee-298c693a4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lora\n",
    "# lora_config = LoraConfig.from_pretrained('lora/llama')\n",
    "# model = get_peft_model(model, lora_config)\n",
    "# model.config.use_cache = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
