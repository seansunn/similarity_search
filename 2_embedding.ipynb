{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa0b0d4-4bfc-4257-8be4-0403eb682de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\ProgramData\\Miniconda\\envs\\qlora\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings, HuggingFaceBgeEmbeddings\n",
    "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          AutoTokenizer,\n",
    "                          GenerationConfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e2f408-e5bd-4cbc-9779-6b0963878a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def get_embeddings(self, text):\n",
    "        inputs = self.tokenizer.batch_encode_plus(text,\n",
    "                                                  padding=True,\n",
    "                                                  return_tensors=\"pt\",\n",
    "                                                  max_length=512,\n",
    "                                                  truncation=True).to(\"cuda\")\n",
    "        attn_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        outputs = self.model(**inputs, output_hidden_states=True)\n",
    "        last_layer_hidden = outputs.hidden_states[-1]\n",
    "        mask = attn_mask.unsqueeze(-1).expand(last_layer_hidden.size()).float()\n",
    "        masked_embeddings = last_layer_hidden * mask\n",
    "\n",
    "        # Extract the embedding by mean pooling\n",
    "        embeddings = torch.sum(masked_embeddings, dim=1)\n",
    "        seq_length = torch.sum(mask, dim=1)\n",
    "        embedding = embeddings / seq_length\n",
    "        return F.normalize(embedding, p=2, dim=1).tolist()\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self.get_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.get_embeddings([query])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26f1e09-6aec-4eb4-92d3-d05481da0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.doc_ids = dataset['docs']['doc_id']\n",
    "        self.query_ids = dataset['qrels']['query_id']\n",
    "        self.doc_idx = {sample['doc_id']: idx for idx, sample in enumerate(dataset['docs'])}\n",
    "        self.query_idx = {sample['query_id']: idx for idx, sample in enumerate(dataset['qrels'])}\n",
    "\n",
    "    def get_doc(self, doc_id):\n",
    "        idx = self.doc_idx.get(doc_id)\n",
    "        if idx is not None:\n",
    "            return self.dataset['docs'][idx]['doc_str']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_qa(self, query_id):\n",
    "        idx = self.query_idx.get(query_id)\n",
    "        if idx is not None:\n",
    "            return self.dataset['qrels'][idx]['query'], self.dataset['qrels'][idx]['rel_doc_ids']\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ace1bb-fb5e-4dc0-8480-303ca55a4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(dataset,\n",
    "                     database,\n",
    "                     batch_size=4,\n",
    "                     store_per_n_docs=64\n",
    "                    ):\n",
    "\n",
    "    doc_ids = set(dataset['docs']['doc_id'])\n",
    "    stored_ids = set(database.get()['ids'])\n",
    "    unstored_docs = list(doc_ids - stored_ids)\n",
    "    len_unstored_docs = len(unstored_docs)\n",
    "\n",
    "    print(f\"NO. of documents in the dataset:  {len(doc_ids)}\")\n",
    "    print(f\"NO. of unstored document:         {len(unstored_docs)}\\n\")\n",
    "\n",
    "    if len_unstored_docs == 0:\n",
    "        print(\"All documents and embeddings are stored.\\n\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Storing documents and embeddings into database...\\n\")\n",
    "        dret = Retriever(dataset)\n",
    "        processed_docs = 0\n",
    "        for i in tqdm(range(0, len_unstored_docs, batch_size), desc=\"Processing docs\"):\n",
    "            end_idx = min(i + batch_size, len_unstored_docs)\n",
    "            doc_ids = unstored_docs[i:end_idx]\n",
    "            doc_str = [dret.get_doc(doc_id) for doc_id in doc_ids]\n",
    "            database.add_texts(texts=doc_str,\n",
    "                               metadatas=[{'doc_id': doc_id} for doc_id in doc_ids],\n",
    "                               ids=doc_ids)\n",
    "\n",
    "            processed_docs += len(doc_ids)\n",
    "            if processed_docs % store_per_n_docs == 0:\n",
    "                database.persist()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        database.persist()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Process completed. NO. of documents in the database: {database._collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e55893-3447-4808-816e-6a0aeec715c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = load_from_disk('data/eval_nf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90112a9-3a9c-4b0e-b955-5e9b63744663",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = 100  # 20 40 60 80 100\n",
    "lora_rank = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae73fb1-ad4e-43b5-be5e-678daaf53331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a367fdc929416cb7ea1318d03dba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"llms/Llama-2-13b-chat-hf\"\n",
    "adapter_path = f\"checkpoints/llama_{lora_rank}/checkpoint-{ckpt}\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bedfb15-0b5c-4cc7-8158-8a19439d33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_embedding = CustomEmbedding(model, tokenizer)\n",
    "\n",
    "nf_llama = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_llama_qlora_best_f1',\n",
    "    embedding_function=llama_embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06379121-4c7c-4d05-a20a-bf4ed3dce0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of documents in the dataset:  3633\n",
      "NO. of unstored document:         3633\n",
      "\n",
      "Storing documents and embeddings into database...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing docs: 100%|██████████| 909/909 [08:48<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed. NO. of documents in the database: 3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "store_embeddings(dataset=nf,\n",
    "                 database=nf_llama,\n",
    "                 batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6702f534-c71a-457d-89c8-90b7d2281165",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "nf_hf = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_hf',\n",
    "    embedding_function=hf_embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51df12d9-ddad-4347-aecf-30634dfb72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of documents in the dataset:  3633\n",
      "NO. of unstored document:         3633\n",
      "\n",
      "Storing documents and embeddings into database...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing docs: 100%|██████████| 909/909 [00:36<00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed. NO. of documents in the database: 3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "store_embeddings(dataset=nf,\n",
    "                 database=nf_hf,\n",
    "                 batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45a3e76c-bd92-4678-a9ed-9bb38a10180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_bge_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en\",\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "nf_hf_bge = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_hf_bge',\n",
    "    embedding_function=hf_bge_norm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d18917c-de5c-4ad0-8043-f13ad4192893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of documents in the dataset:  3633\n",
      "NO. of unstored document:         3633\n",
      "\n",
      "Storing documents and embeddings into database...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing docs: 100%|██████████| 909/909 [00:29<00:00, 30.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed. NO. of documents in the database: 3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "store_embeddings(dataset=nf,\n",
    "                 database=nf_hf_bge,\n",
    "                 batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe405d0-800d-4f41-af3c-d0ddcdae31c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
