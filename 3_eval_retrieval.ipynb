{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9395c2b4-713b-4e98-a4f8-9201ee8a1302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda\\envs\\qlora\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\ProgramData\\Miniconda\\envs\\qlora\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings, HuggingFaceBgeEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, TFIDFRetriever\n",
    "from langchain.schema import Document\n",
    "import pinecone\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          AutoTokenizer,\n",
    "                          GenerationConfig)\n",
    "\n",
    "\n",
    "load_dotenv();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06d2d33-76b5-4bbf-9419-6280a3537348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def get_embeddings(self, text):\n",
    "        inputs = self.tokenizer.batch_encode_plus(text, padding=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "        attn_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        outputs = self.model(**inputs, output_hidden_states=True)\n",
    "        last_layer_hidden = outputs.hidden_states[-1]\n",
    "        mask = attn_mask.unsqueeze(-1).expand(last_layer_hidden.size()).float()\n",
    "        masked_embeddings = last_layer_hidden * mask\n",
    "\n",
    "        # Extract the embedding by mean pooling\n",
    "        embeddings = torch.sum(masked_embeddings, dim=1)\n",
    "        seq_length = torch.sum(mask, dim=1)\n",
    "        embedding = embeddings / seq_length\n",
    "\n",
    "        # L2 normalization to have magnitude of 1\n",
    "        return F.normalize(embedding, p=2, dim=1).tolist()\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self.get_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.get_embeddings([query])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a10839-abe4-44f3-b1e8-50f87d1b35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.doc_ids = dataset['docs']['doc_id']\n",
    "        self.query_ids = dataset['qrels']['query_id']\n",
    "        self.doc_idx = {sample['doc_id']: idx for idx, sample in enumerate(dataset['docs'])}\n",
    "        self.query_idx = {sample['query_id']: idx for idx, sample in enumerate(dataset['qrels'])}\n",
    "\n",
    "    def get_doc(self, doc_id):\n",
    "        idx = self.doc_idx.get(doc_id)\n",
    "        if idx is not None:\n",
    "            return self.dataset['docs'][idx]['doc_str']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_qa(self, query_id):\n",
    "        idx = self.query_idx.get(query_id)\n",
    "        if idx is not None:\n",
    "            return self.dataset['qrels'][idx]['query'], self.dataset['qrels'][idx]['rel_doc_ids']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def binary_relevance_labeling(results, answers, result_len=1000):\n",
    "    result_array = np.zeros(result_len, dtype=int)\n",
    "    for i in range(result_len):\n",
    "\n",
    "        if type(results[0]) == Document:\n",
    "            result_doc_id = results[i].metadata['doc_id']\n",
    "        else:\n",
    "            result_doc_id = results[i][0].metadata['doc_id']\n",
    "\n",
    "        if result_doc_id in answers:\n",
    "            result_array[i] = 1\n",
    "    return result_array\n",
    "\n",
    "\n",
    "def average_precision(results_array, num_rel_docs):\n",
    "    relevant_idx = np.where(results_array == 1)[0]\n",
    "    precisions = np.cumsum(results_array)[relevant_idx] / (relevant_idx + 1)\n",
    "    AP = np.sum(precisions) / num_rel_docs\n",
    "    return AP\n",
    "\n",
    "\n",
    "def evaluation_mAP_embedding(dataset, database, search_func='cos_sim', k=1000):\n",
    "    qlist = dataset['qrels']['query_id']\n",
    "    qlen = len(qlist)\n",
    "    qret = DatasetRetriever(dataset)\n",
    "    ap_arr = np.zeros(qlen, dtype=float)\n",
    "\n",
    "    cos_sim_kwargs = {'k': k}\n",
    "    mmr_kwargs = {'k': k, 'fetch_k': 5*k}\n",
    "\n",
    "    search_functions = {\n",
    "        'cos_sim': database.similarity_search_with_score,\n",
    "        # WIP: needs some fix on mmr\n",
    "        'mmr': database.max_marginal_relevance_search\n",
    "    }\n",
    "\n",
    "    search = search_functions.get(search_func, search_func)\n",
    "\n",
    "    for i in tqdm(range(qlen), desc=\"Processing queries\"):\n",
    "        query, answers = qret.get_qa(qlist[i])\n",
    "        current_kwargs = cos_sim_kwargs if search_func != 'mmr' else mmr_kwargs\n",
    "        q_result = search(query, **current_kwargs)\n",
    "        result_arr = binary_relevance_labeling(q_result, answers, result_len=k)\n",
    "        ap = average_precision(result_arr, len(answers))\n",
    "        ap_arr[i] = ap\n",
    "\n",
    "    mAP = np.mean(ap_arr)\n",
    "    print(f\"The mAP is {mAP:.3f}\")\n",
    "\n",
    "\n",
    "def evaluation_mAP_retriever(dataset, retriever, k=1000, reorder=False):\n",
    "    qlist = dataset['qrels']['query_id']\n",
    "    qlen = len(qlist)\n",
    "    qret = DatasetRetriever(dataset)\n",
    "    ap_arr = np.zeros(qlen, dtype=float)\n",
    "    retriever = retriever.from_documents(\n",
    "        [Document(page_content=i['doc_str'], metadata={'doc_id': i['doc_id']}) for i in dataset['docs']]\n",
    "    )\n",
    "\n",
    "    retriever.k = k\n",
    "\n",
    "    for i in tqdm(range(qlen), desc=\"Processing queries\"):\n",
    "        query, answers = qret.get_qa(qlist[i])\n",
    "        q_result = retriever.get_relevant_documents(query)\n",
    "        result_arr = binary_relevance_labeling(q_result, answers, result_len=k)\n",
    "        ap = average_precision(result_arr, len(answers))\n",
    "        ap_arr[i] = ap\n",
    "\n",
    "    mAP = np.mean(ap_arr)\n",
    "    print(f\"The mAP@{k} is {mAP:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862b7130-936c-49d6-84fc-edcfc0e79d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = load_from_disk('data/eval_nf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71de700-a255-4851-bf5e-0b7e619d0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = 60  # 20 40 60 80 100\n",
    "lora_rank = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7d3f07-871a-4f8f-832f-906f4631007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd03f2fcca54cb998e7bf6fd7535770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"llms/Llama-2-13b-chat-hf\"\n",
    "adapter_path = f\"checkpoints/llama_{lora_rank}/checkpoint-{ckpt}\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f9c1b3-3656-4acf-875f-b7ab8b4098c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_embedding = CustomEmbedding(model, tokenizer)\n",
    "\n",
    "nf_llama = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_llama_qlora_best_bertscore',\n",
    "    embedding_function=llama_embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fbb34-744b-4041-8054-a22b496afbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [01:20<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries:  28%|██▊       | 89/323 [00:21<00:56,  4.12it/s]"
     ]
    }
   ],
   "source": [
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_llama,\n",
    "    search_func='cos_sim',\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_llama,\n",
    "    search_func='cos_sim',\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17165b-723c-44d4-9092-3bbd05375054",
   "metadata": {},
   "source": [
    "## Sentence Transformers all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b2c022-18a9-433c-9231-5fda17200321",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089c71f-1cf4-4d1a-86bd-cd7d72055182",
   "metadata": {},
   "source": [
    "### 1. Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6abb88-e9fc-462e-a184-888e01592de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [04:11<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:33<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENV')\n",
    ")\n",
    "\n",
    "nf_hf_pinecone = Pinecone(\n",
    "    index=pinecone.Index('sentense-transformers'),\n",
    "    embedding=hf_embedding,\n",
    "    text_key='text'\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf_pinecone,\n",
    "    search_func='cos_sim',\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf_pinecone,\n",
    "    search_func='cos_sim',\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f81dd-d6c1-4b7c-891a-7c4bbb56e7f2",
   "metadata": {},
   "source": [
    "### 2. Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be9a572-c428-47b0-9220-6e4c242a5361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:05<00:00, 57.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:01<00:00, 201.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nf_hf = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_hf',\n",
    "    embedding_function=hf_embedding\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf,\n",
    "    search_func='cos_sim',\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf,\n",
    "    search_func='cos_sim',\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53985af-10cf-4458-84d4-ca99881b8d01",
   "metadata": {},
   "source": [
    "## BGE-base-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e7e5d1-c069-427d-8d4a-31c13eb8d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:03<00:00, 92.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:02<00:00, 118.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP is 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hf_bge_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en\",\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "nf_hf_bge = Chroma(\n",
    "    collection_name='nf_eval',\n",
    "    persist_directory='database/nf_hf_bge',\n",
    "    embedding_function=hf_bge_norm\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf_bge,\n",
    "    search_func='cos_sim',\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_embedding(\n",
    "    dataset=nf,\n",
    "    database=nf_hf_bge,\n",
    "    search_func='cos_sim',\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9e1af-8378-444e-a57d-45e0bd123968",
   "metadata": {},
   "source": [
    "## Word frequency based retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d911f8d-654b-4693-a031-46abda02e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:00<00:00, 564.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP@100 is 0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:00<00:00, 592.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP@10 is 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_mAP_retriever(\n",
    "    dataset=nf,\n",
    "    retriever=BM25Retriever,\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_retriever(\n",
    "    dataset=nf,\n",
    "    retriever=BM25Retriever,\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f800b7-9205-471d-9922-94a3a4688dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:01<00:00, 285.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP@100 is 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 323/323 [00:01<00:00, 284.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mAP@10 is 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_mAP_retriever(\n",
    "    dataset=nf,\n",
    "    retriever=TFIDFRetriever,\n",
    "    k=100\n",
    ")\n",
    "\n",
    "evaluation_mAP_retriever(\n",
    "    dataset=nf,\n",
    "    retriever=TFIDFRetriever,\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a64398-b4de-48f7-8737-393fad610862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
