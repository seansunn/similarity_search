{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b039e326-8659-4a6d-aa32-c4dbb40ef265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\ProgramData\\Miniconda\\envs\\qlora\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from bert_score import score\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          AutoTokenizer,\n",
    "                          GenerationConfig,\n",
    "                          pipeline)\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd41b4e-84a2-418f-ac4f-b302ad39f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = 60  # 20 40 60 80 100\n",
    "lora_rank = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179439ab-8d53-421e-8583-8713494d20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('data/finetuning_llama')['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d1353a-7dfc-4bab-a7e7-c1383a82806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 50, 'yes': 50}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = {}\n",
    "for i in dataset['answer']:\n",
    "    accum[i] = accum.get(i, 0) + 1\n",
    "\n",
    "accum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55de123-316c-4374-bb0e-a312087683dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46056f4925724c90b9d959fb5c101ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_path = \"llms/vicuna-13b-v1.5\"\n",
    "model_path = \"llms/Llama-2-13b-chat-hf\"\n",
    "adapter_path = f\"checkpoints/llama_{lora_rank}/checkpoint-{ckpt}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e7ca1d-3c63-4cd4-98e4-4ce314c6a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_answer(text, marker=\"[/INST] \"):\n",
    "    if marker in text:\n",
    "        start_index = text.index(marker) + len(marker)\n",
    "        return text[start_index:].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def llm_batch_generate(prompt, max_token=100, top_p=0.1, temperature=0.1, without_prompt=True):\n",
    "    inputs = tokenizer.batch_encode_plus(prompt, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "                **inputs,\n",
    "                generation_config=GenerationConfig(\n",
    "                    do_sample=True,\n",
    "                    max_new_tokens=max_token,\n",
    "                    top_p=top_p,\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "        )\n",
    "\n",
    "    text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    if without_prompt:\n",
    "        if type(text)==list:\n",
    "            return [keep_answer(i) for i in text]\n",
    "        else:\n",
    "            return keep_answer(text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57038ef1-e03e-4e20-9e14-27be372f538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(dataset, batch_size=2):\n",
    "    pred_list = []\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Generating answers\"):\n",
    "        end_idx = min(i + batch_size, len(dataset))\n",
    "        batch = dataset[i:end_idx]\n",
    "        pred_list += llm_batch_generate(batch['conversation'])\n",
    "    return pred_list\n",
    "\n",
    "\n",
    "def binary_result(pred_list, true_list):\n",
    "    result = [true_ans if true_ans in pred_ans.lower()[:10]\n",
    "              else ('no' if true_ans=='yes' else 'yes')\n",
    "              for pred_ans, true_ans in zip(pred_list, true_list)]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b97977-f618-4f79-bd60-391df279cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████| 50/50 [13:54<00:00, 16.69s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_long_answer = generate_result(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ab9bce-689b-4a9f-8216-0788b566b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/pred_long_llama_{lora_rank}_ckpt_{ckpt}.pkl', 'wb') as f:\n",
    "    pickle.dump(pred_long_answer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0646950-0494-4458-a162-20f1d95afbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/pred_long_llama_{lora_rank}_ckpt_{ckpt}.pkl', 'rb') as f:\n",
    "    pred_long_answer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d951e-cce7-4c62-bcf3-925bc8b54861",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_binary = dataset['answer']\n",
    "pred_binary = binary_result(pred_long_answer, true_binary)\n",
    "true_long_answer = dataset['full_answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354908f4-1749-408b-84aa-055659a224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.899\n"
     ]
    }
   ],
   "source": [
    "short_ans_score = f1_score(true_binary, pred_binary, pos_label=\"yes\")\n",
    "print(f\"f1 score: {short_ans_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331644e4-d063-4eac-bff2-58c6836ec2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore: 0.437\n"
     ]
    }
   ],
   "source": [
    "Precision, Recall, F1 = score(\n",
    "    pred_long_answer, true_long_answer, lang='en',\n",
    "    model_type='microsoft/deberta-xlarge-mnli',\n",
    "    rescale_with_baseline=True)\n",
    "\n",
    "print(f'Average BERTScore: {torch.mean(F1).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f06a535c-db60-45d0-bd63-6530dc3e1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pair(idx):\n",
    "    print(f\"True: {true_long_answer[idx]}\\n\\nPred: {pred_long_answer[idx]}\\n\\nBERTScore: {F1[idx].item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "586dc4e8-ccf9-4e30-8915-4bbc242ac8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: No. Preoperative pulmonary embolism is not associated with worse early mortality, recurrence or cancer specific survival in patients with renal cell carcinoma and tumor thrombus.\n",
      "\n",
      "Pred: No. Preoperative pulmonary embolism is not associated with poor postoperative outcomes in patients with renal cell carcinoma and venous thrombus.\n",
      "\n",
      "BERTScore: 0.721\n"
     ]
    }
   ],
   "source": [
    "print_pair(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97825d87-b140-45f4-b7f9-ee40fa0a2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: Yes. These results indicate that a higher rate of eating is positively and independently associated with circulating IL-1β concentrations in Japanese men not being treated for metabolic diseases.\n",
      "\n",
      "Pred: $}}% Yes. Our findings suggest that a higher rate of eating is associated with higher circulating IL-1β concentrations in Japanese men not being treated for metabolic diseases.\n",
      "\n",
      "BERTScore: 0.828\n"
     ]
    }
   ],
   "source": [
    "print_pair(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4811e98-dc02-4f25-9d6f-f3710d70a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: No. Non-compliance to the guideline is more common in older patients and in patients with melanoma in the head and neck region. After adjusting for confounders, a significant effect of complying with the guidelines on overall survival could not be observed.\n",
      "\n",
      "Pred: $}}% No. The results of this study suggest that non-compliance with the guideline for re-excision of CMM does not have a significant impact on survival.\n",
      "\n",
      "BERTScore: 0.305\n"
     ]
    }
   ],
   "source": [
    "print_pair(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "195f1562-50bc-4de4-a3ea-d444ca66a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: Yes. Partial inhibition of TGF-beta using alpha(v)beta6 integrin antibodies is effective in blocking murine pulmonary fibrosis without exacerbating inflammation. In addition, the elevated expression of alpha(v)beta6, an activator of the fibrogenic cytokine, TGF-beta, in human pulmonary fibrosis suggests that alpha(v)beta6 monoclonal antibodies could represent a promising new therapeutic strategy for treating pulmonary fibrosis.\n",
      "\n",
      "Pred: Yes. Inhibition of alpha(v)beta6-mediated TGF-beta activation may be a useful therapeutic strategy for pulmonary fibrosis, as it may be possible to inhibit TGF-beta at sites of alpha(v)beta6 up-regulation without affecting other homeostatic roles of TGF-beta.\n",
      "\n",
      "BERTScore: 0.352\n"
     ]
    }
   ],
   "source": [
    "print_pair(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0111ffe-c6a0-481e-a69a-1c39931181c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: Yes. DDR appears feasible and acceptable to minority youth. DDR may increase moderate-vigorous physical activity and improve physical fitness in at-risk populations.\n",
      "\n",
      "Pred: Yes. This study suggests that DDR may be a feasible and acceptable way to increase physical fitness in minority elementary school youth.\n",
      "\n",
      "BERTScore: 0.570\n"
     ]
    }
   ],
   "source": [
    "print_pair(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4681b3a-1388-47e3-a420-1eea12924653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r128@020 step: f1 - 0.333; BERTScore - 0.392\n",
    "# r128@040 step: f1 - 0.881; BERTScore - 0.411\n",
    "# r128@060 step: f1 - 0.899; BERTScore - 0.437\n",
    "# r128@080 step: f1 - 0.918; BERTScore - 0.417\n",
    "# r128@100 step: f1 - 0.922; BERTScore - 0.350\n",
    "\n",
    "# r064@020 step: f1 - 0.462; BERTScore - 0.402\n",
    "# r064@040 step: f1 - 0.862; BERTScore - 0.419\n",
    "# r064@060 step: f1 - 0.923; BERTScore - 0.427\n",
    "# r064@080 step: f1 - 0.896; BERTScore - 0.411\n",
    "# r064@100 step: f1 - 0.931; BERTScore - 0.360\n",
    "\n",
    "# base           f1 - 0.400; BERTScore - 0.209\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
